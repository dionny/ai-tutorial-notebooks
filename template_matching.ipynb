{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dionny/ai-tutorial-notebooks/blob/main/template_matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27821b0e",
      "metadata": {
        "id": "27821b0e"
      },
      "source": [
        "# Template Matching for Element Localization and Classification\n",
        "\n",
        "Template matching is a powerful tool for image-based element localization and classification. Template matching algorithms take as input two images, a template image (e.g., an element) and a query image (e.g., a screenshot). If the template image appears as a sub-image within the query image, the template matching algorithm will return the coordinates at which the template appears within the query image; some algorithms also return a confidence score or match percentage. There are a wide variety of template matching algorithms in existence. This notebook uses naive template matching algorithms from OpenCV.\n",
        "\n",
        "After running the cell below, use the widget to upload a query image (e.g., a screenshot)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47f32053",
      "metadata": {
        "id": "47f32053"
      },
      "outputs": [],
      "source": [
        "import ipywidgets\n",
        "\n",
        "screenshot_uploader = ipywidgets.FileUpload(\n",
        "    accept='.png',\n",
        "    multiple=False,\n",
        ")\n",
        "display(screenshot_uploader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9860c28",
      "metadata": {
        "id": "c9860c28"
      },
      "source": [
        "After running the cell below, use the widget to upload a template image (e.g., a cropped screen element from the screenshot image). The image should have the same scale as the query image (i.e., do not re-scale the template image after cropping), otherwise, the algorithms used below will be unable to localize the template in the query image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7e0389b",
      "metadata": {
        "id": "e7e0389b"
      },
      "outputs": [],
      "source": [
        "template_uploader = ipywidgets.FileUpload(\n",
        "    accept='.png',\n",
        "    multiple=False,\n",
        ")\n",
        "display(template_uploader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3b46d5b",
      "metadata": {
        "id": "e3b46d5b"
      },
      "source": [
        "Visualize the template and query images by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e58ade8b",
      "metadata": {
        "scrolled": true,
        "id": "e58ade8b"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "import notebook_utils\n",
        "\n",
        "# Get uploaded images.\n",
        "screenshot_image = notebook_utils.get_uploaded_image(screenshot_uploader)\n",
        "template_image = notebook_utils.get_uploaded_image(template_uploader)\n",
        "\n",
        "# Populate grid with titles and images.\n",
        "num_columns = 2\n",
        "grid_gap = '30px'\n",
        "title_grid = ipywidgets.GridspecLayout(1, num_columns, grid_gap=grid_gap)\n",
        "column_titles = ['Screenshot Image', 'Template Image']\n",
        "for i, column_title in enumerate(column_titles):\n",
        "    title_grid[0, i] = ipywidgets.HTML(value='<h1>{text}</h1>'.format(text=column_title))\n",
        "grid = ipywidgets.GridspecLayout(1, num_columns, grid_gap=grid_gap)\n",
        "grid[0, 0] = ipywidgets.Image(value=notebook_utils.convert_image_to_bytes(screenshot_image), max_width='50%')\n",
        "grid[0, 1] = ipywidgets.Image(value=notebook_utils.convert_image_to_bytes(template_image), max_width='50%')\n",
        "\n",
        "# Display grid.\n",
        "display(title_grid)\n",
        "display(grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "390080dd",
      "metadata": {
        "id": "390080dd"
      },
      "source": [
        "The cell below uses a template matching algorithm from OpenCV to create an element classifier that will detect the presence of the template in the screenshot image and localize the template within the screenshot image. You can experiment by adjusting the confidence threshold, [template matching comparison method](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_template_matching/py_template_matching.html), using [canny edges](https://docs.opencv.org/master/da/d22/tutorial_py_canny.html) and converting to grayscale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd7c562",
      "metadata": {
        "scrolled": true,
        "id": "edd7c562"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from IPython.display import Markdown\n",
        "import numpy\n",
        "\n",
        "\n",
        "class TemplateMatcher(object):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        threshold=0.9,\n",
        "        comparison_method=cv2.TM_CCOEFF_NORMED,\n",
        "        use_canny=False,\n",
        "        use_grayscale=False,\n",
        "    ):\n",
        "        self.threshold = threshold\n",
        "        self.comparison_method = comparison_method\n",
        "        self.use_canny = use_canny\n",
        "        self.use_grayscale = use_grayscale\n",
        "\n",
        "    @staticmethod\n",
        "    def _convert_to_numpy_array_if_necessary(image):\n",
        "        if isinstance(image, PIL.Image.Image):\n",
        "            image = numpy.array(image)\n",
        "        return image\n",
        "\n",
        "    def _convert_to_canny_if_option_set(self, image):\n",
        "        if self.use_canny:\n",
        "            image = cv2.Canny(image, 50, 200)\n",
        "        return image\n",
        "\n",
        "    def _convert_to_grayscale_if_option_set(self, image):\n",
        "        if self.use_grayscale:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "        return image\n",
        "\n",
        "    def _preprocess_image(self, image):\n",
        "        image = self._convert_to_numpy_array_if_necessary(image)\n",
        "        image = self._convert_to_grayscale_if_option_set(image)\n",
        "        image = self._convert_to_canny_if_option_set(image)\n",
        "        return image\n",
        "\n",
        "    def fit(self, query_image):\n",
        "        self.query_image = self._preprocess_image(query_image)\n",
        "\n",
        "    def predict(self, template_image):\n",
        "        template_image = self._preprocess_image(template_image)\n",
        "        match = cv2.matchTemplate(self.query_image, template_image, self.comparison_method)\n",
        "        _, confidence_score, _, coordinates = cv2.minMaxLoc(match)\n",
        "        match_found = confidence_score >= self.threshold\n",
        "        return match_found, confidence_score, coordinates\n",
        "\n",
        "\n",
        "# Experiment by changing the threshold, comparison method, canny and grayscale settings below.\n",
        "threshold = 0.95  # The confidence threshold can be adjusted to values between 0 and 1.\n",
        "use_canny = False  # Specify whether to use canny edges.\n",
        "use_grayscale = False  # Specify whether to use grayscale image.\n",
        "\n",
        "# The following are valid values for the comparison method:\n",
        "#     cv2.TM_CCOEFF\n",
        "#     cv2.TM_CCOEFF_NORMED\n",
        "#     cv2.TM_CCORR\n",
        "#     cv2.TM_CCORR_NORMED\n",
        "comparison_method = cv2.TM_CCOEFF_NORMED\n",
        "\n",
        "# Run the classifier with the uploaded screenshot and template images.\n",
        "template_matcher = TemplateMatcher(\n",
        "    threshold=threshold,\n",
        "    comparison_method=comparison_method,\n",
        "    use_canny=use_canny,\n",
        "    use_grayscale=use_grayscale,\n",
        ")\n",
        "template_matcher.fit(screenshot_image)\n",
        "match_found, confidence_score, coordinates = template_matcher.predict(template_image)\n",
        "\n",
        "# Display results of classification.\n",
        "if match_found:\n",
        "    # Populate grid.\n",
        "    grid = ipywidgets.GridspecLayout(1, 2, grid_gap=grid_gap)\n",
        "    title_grid = ipywidgets.GridspecLayout(1, num_columns, grid_gap=grid_gap)\n",
        "    column_titles = ['Screenshot Image', 'Confidence Score']\n",
        "    for i, column_title in enumerate(column_titles):\n",
        "        title_grid[0, i] = ipywidgets.HTML(value='<h1>{text}</h1>'.format(text=column_title))\n",
        "    top_left = coordinates\n",
        "    bottom_right = notebook_utils.get_bottom_right(template_image, top_left)\n",
        "    screenshot_with_bounding_box = notebook_utils.draw_bounding_box(screenshot_image, top_left, bottom_right)\n",
        "    grid[0, 0] = ipywidgets.Image(value=notebook_utils.convert_image_to_bytes(screenshot_with_bounding_box), max_width='50%')\n",
        "    grid[0, 1] = ipywidgets.Label('Score: {confidence_score}'.format(confidence_score=confidence_score))\n",
        "\n",
        "    # Display results.\n",
        "    display(title_grid)\n",
        "    display(grid)\n",
        "else:\n",
        "    # Display message indicating no match found.\n",
        "    message = 'No matches, confidence score {confidence_score} below the threshold. Try adjusting the values above or upload new images.'.format(confidence_score=confidence_score)\n",
        "    display(Markdown(message))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6612741e",
      "metadata": {
        "id": "6612741e"
      },
      "source": [
        "The naive template matching algorithms used above are computationally inexpensive and have excellent [precision](https://en.wikipedia.org/wiki/Precision_and_recall#Precision) when used as element classifiers. However, they require the template and query images to have the same scale, otherwise, they will be unable to localize the template within the query image. This is a major drawback in the context of AI-based testing, since screenshots taken from different devices will typically differ in scale. Scale-invariant template matching algorithms exist that generalize across varying screen resolutions."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}